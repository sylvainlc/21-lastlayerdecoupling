\documentclass[journal]{IEEEtran}

% Packages
\usepackage{amsmath} % Math environments
\usepackage{amsfonts, dsfont} % Math fonts
\usepackage{hyperref} % Links
\usepackage{graphicx} % Include graphics
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{booktabs,xcolor}
\usepackage[ruled,vlined]{algorithm2e}
\graphicspath{ {./images/} }

\title{Last layer state space model for representation learning and uncertainty quantification}

\author{Max Cohen, Maurice Charbit and Sylvain Le Corff
	\thanks{This work was supported by grants from RÃ©gion Ile-de-France.}
	\thanks{Max Cohen is with with Samovar, T\'el\'ecom SudParis, CITI, TIPIC, Institut Polyechnique de Paris, (e-mail: \{max.cohen, sylvain.le\_corff\}@telecom-sudparis.eu).}
	\thanks{Maurice Charbit is with Accenta, Boulogne-Billancourt (e-mail: mch@oze-energies.com).}}

\begin{document}
\maketitle
\begin{abstract}
	As sequential neural architectures become deeper and more complex, uncertainty estimation is more and more challenging.
	Efforts in quantifying uncertainty often rely on specific training procedures, and bear additional computational costs due to the dimensionality of such models.
	In this letter, we propose to decompose a classification or regression task in two steps: a representation learning stage to learn low-dimensional states, and a state space model for uncertainty estimation.
	This approach allows to separate representation learning and design of generative models.
	We demonstrate how predictive distributions can be estimated on top of an existing and trained neural network, by adding a state space-based last layer whose parameters are estimated with Sequential Monte Carlo methods.
	We apply our proposed methodology to the hourly estimation of Electricity Transformer Oil temperature, a publicly benchmarked dataset.
	Our model accounts for the noisy data structure, due to unknown or unavailable variables, and is able to provide confidence intervals on predictions.
\end{abstract}

\begin{IEEEkeywords}
	Recurrent neural networks, Representation learning, Uncertainty quantification, Sequential Monte Carlo.
\end{IEEEkeywords}

\section{Introduction}
\label{sec:intro}
% We believe a deeper understanding of \ensuremath{\mathrm{CO_2}} variations can assist in regulating and reducing HVAC consumption, while improving well being.

Recurrent Neural Networks (RNN) were first introduced as an efficient and convenient architecture to address short time dependencies problems.
They have been consistently improved to develop longer term memory, and optimize their implementations \cite{Bengio1994LearningLD,Hochreiter1997LongSM}. %,Cho2014LearningPR}.
Current deep learning frameworks allow stacking arbitrary high number of recurrent layers, whose parameters are estimated by gradient descent through automated differentiation procedures, as shown in \cite{Graves2013SpeechRecognition}.
However, many critical applications, such as medical diagnosis or drug design discovery, require not only accurate predictions, but a good estimate of their uncertainty (\cite{Crowson2016AssessingCalibration, Mervin2020UncertaintyQuantification}).
Fostering the dissemination of deep learning-based algorithms to such fields requires to design new approaches for uncertainty quantification.

In this context, Bayesian statistics are able to approximate the distributions of future observations and to provide uncertainty estimation \cite{Hinton1995BayesianLF}.
Several architectures inspired by Variational Inference (VI, see \cite{Jordan2004AnIT}) emerged by considering latent states as random variables and approximating their posterior distribution.
The authors of \cite{Chung2015NIPS} built on a traditional RNN architecture by modelling temporal dependencies between these latent random states.
Results presented in \cite{Fortunato2017bayesian} yield improved performances when considering local gradient information for computing the posterior.
%Similarly, introducing random variables directly into a neural network weights can mitigate overconfidence, as demonstrated by the authors of \cite{Hinton1993}.
In \cite{Blundell2015}, the authors considered weights as random variables and proposed approximations of their posterior distributions allowing more robust predictions on unseen data.

%Variational methods display encouraging results for modelling uncertainty in existing models, but require significant alteration of the model, as well as its training mechanism.
Monte Carlo Dropout (MC Dropout) methods offer to capture uncertainty by leveraging Dropout during both training and evaluation tasks, producing variable predictions from a single trained recurrent model, see \cite{Gal2016NIPS}.
In the following years, MC Dropout methods have been applied in many industrial fields, such as flight delay prediction \cite{Vandal2018} or molecular simulations \cite{Wen2020UncertaintyQI}.
Alternatively, ensemble methods consist in training distinct networks to obtain a combined prediction, as shown in \cite{Pearce2018}.
However, these frequentist approaches fail to guarantee proper calibration of the model, as highlighted by \cite{ashukha2020pitfalls}, and suffer various limitations, see \cite{Fong2020}.

In an effort to provide an alternative strategy with limited computation overhead, \cite{Brosse2020OnLA} suggests splitting training in two stages to solve classification problems for independent data: representation learning and uncertainty estimation. The two steps proceed as follows: (i) the algorithm first trains a deep classifier to obtain accurate task-dependent representations of the data, and then (ii) ensemble models are trained using these representations and the output. Their experiments indicate that last-layer algorithms outperform baseline networks and that a single last layer is an appealing trade-off between computational cost and uncertainty quantification. However, this method is restricted to independent and identically distributed data and cannot be directly applied to time series.


Inspired by \cite{Brosse2020OnLA}, we propose a last layer approach to split uncertainty quantification from representation learning, in the context of dependent data. This new method for uncertainty estimation combines high expressivity, quality uncertainty estimations and ease of training. Our proposed architecture is composed of an arbitrary sequential model, followed by a decoupled state space model layer. Using a state space model in the last layer allows to introduce complex predictive distributions for the observations based on task-dependent latent data. However, because the log likelihood of the observations is not available explicitly in such a setting, the second stage training requires using approximate sampling methods. In this letter, we explore Sequential Monte Carlo methods, which were already successfully combined with recurrent neural networks to tackle variable sequential problems, see for instance \cite{Ma2020}.
We turn to \cite{Martin2020TheMC} for an example using more complex neural architectures, such as Transformer.
Particle filters have also proven reliable in other fields, such as presented in \cite{Liu2020LSTMPF} for object tracking.



%The former can be fitted through a traditional gradient descent iteration, while the latter is trained using Sequential Monte Carlo methods.
%Our uncertainty estimation layer can thus be built on top of an existing, already trained model. The model is presented in Section~\ref{sec:decoupling} and numerical experiments are displayed in Section~\ref{sec:exp}.

\section{Last layer decoupling}
Estimating the parameters of potentially high-dimensional models with unobserved (i.e. noisy) layers is a challenging task.
We therefore propose to first train an input model following traditional deep learning approaches, then use Monte Carlo methods in a lower dimensional state space to account for uncertainty in the last layer.

In the following, for any sequence $(a_m,\ldots, a_n)$ with $n\geq m$, we use the short-hand notation $a_{m:n} = (a_m,\ldots, a_n)$.
Let $T\ge 1$ be a given time horizon.
Lastly, we denote by $\Psi_{\mu, \Sigma}$ the Gaussian probability density function with mean vector $\mu$ and covariance matrix $\Sigma$.
We consider the regression task over observations $Y_{1:T}$ associated with the inputs $U_{1:T}$.

\subsection{Representation learning}%
In this letter, we consider an arbitrary multi-layer neural network $h$ with unknown parameters $\varphi$, responsible for extracting high level features from the input time series:
\begin{align}
	\widetilde U_{1:T} & = h_\varphi(U_{1:T})& \text{input model}
\end{align}
In order to get an estimate $\hat \varphi$, we introduce an auxiliary function $k_\psi$ and generate predictions $\hat Y_t = k_\psi(Y_{t-1}, \widetilde U_t)\,, \forall 1 \leq t \leq T$.
The input model can then be trained by performing gradient descent to minimize the prediction error, before discarding the auxiliary function.

\subsection{State space model}
\label{sub:proposed_architecture}
We define a state space model taking as input the previously extracted features $\widetilde U_{1:T}$.
Let $X_{1:T}$ a sequence of stochastic hidden states computed recursively and $Y_t$ their associated predictions.
For all $t \geq 1$, the model is defined as:
\begin{align}
	X_t            & = g_\theta(X_{t-1}, \widetilde U_t) + \eta_t & \text{state model, }       \\
	Y_t            & = f_\theta(X_t) + \epsilon_t                 & \text{observation model. }
\end{align}
where $\theta$ is a set of real-valued parameters of the network (weights and biases) and $f_\theta$ and $g_\theta$ are non linear parametric functions.
We chose $(\eta_t)_{t\geq 1}$ and $(\epsilon_t)_{t\geq 1}$ as two sequences of i.i.d. centered Gaussian random variables with covariance matrices $\Sigma_x$ and $\Sigma_y$, although any distribution can be substituted.

This decoupled approach aims at reducing the number of parameters in $\theta$, compared to $\varphi$, in order to estimate them using Sequential Monte Carlo methods.
In the next section, we describe this second training procedure for the last layer only, by keeping $\hat \varphi$ fixed.
All implementation and training details are postponed to Section~\ref{sec:exp}.

\section{Sequential Monte Carlo Layer}%
\label{sub:uncertainty_estimation}
In this section, we detail how to estimate the parameters $\theta$, $\Sigma_x$ and $\Sigma_y$ in the model introduced in Section~\ref{sub:proposed_architecture}, from a record of observations $Y_{1:T}$.
This is challenging because the log likelihood of the observations is not available explicitly, as it would require integrating over the distribution of the hidden states $X_{1:T}$.
Consequently, the score function is intractable.
We propose to optimize a Monte Carlo estimator of this score function, using Fisher's identity:
\begin{equation}
	\nabla_\theta \log p_\theta(Y_{1:T}) = \mathbb{E}_\theta \left[ \nabla_\theta\log p_\theta(X_{1:T}, Y_{1:T}) | Y_{1:T} \right]\,,
	\label{eq:grad_ll}
\end{equation}
where $\mathbb{E}_\theta$ design the expectation under the model parameterized by $\widehat \varphi$ and $\theta$ (the dependency on the input $U_{1:T}$ is kept implicit here for better clarity).

\subsection{Particle filter}
The conditional distribution of $X_{1:T}$ given $Y_{1:T}$ is not available explicitly for a nonlinear state space model, but it can be approximated using a family of particles $(\xi^{\ell}_{1:T})_{\ell=1}^N$ associated with importance weights $(\omega^{\ell}_T)_{\ell=1}^N$.
% We first produce a set of histories  associated with importance weights  using the Path-space smoother.
At $k = 0$, $(\xi^{\ell}_0)_{\ell=1}^N$ are sampled independently from $\rho_0 = \Psi_{0, \Sigma_x}$, and each particle $\xi^{\ell}_0$ is associated with the standard importance sampling weight:
\[
	\omega_0^{\ell} \propto \chi\left(\xi^{\ell}_0\right)\ell_0 \left(\xi^{\ell}_0\right)/ \rho_0 \left(\xi^{\ell}_0\right)\,,
\]
where $\ell_0(\cdot) = \Psi_{Y_0, \Sigma_y}(f_\theta(\cdot))$.
Then, for $k\geq 1$, using $\{(\xi^{\ell}_{k-1},\omega^{\ell}_{k-1})\}_{\ell=1}^N$, we sample pairs $\{(I^{\ell}_k,\xi^{\ell}_{k})\}_{\ell=1}^N$ of indices and particles from the instrumental distribution:
\[
	\pi_{k}(\ell,x) \propto \omega_{k-1}^{\ell} p_k(\xi^{\ell}_{k-1},x)\,.
\]
In this application we use for $p_k(\xi^{\ell}_{k-1},\cdot)$ the prior kernel $\Psi_{g_\theta(\xi^\ell_{k-1}, \tilde U_k), \Sigma_x}$.
For $\ell \in \{1,\ldots,N\}$, $\xi^{\ell}_k$ is associated with the importance weight $\omega^{\ell}_k \propto \ell_k(\xi^{\ell}_k)$, where $\ell_k(\cdot) = \Psi_{Y_k, \Sigma_y}(f_\theta(\cdot))$.
The full particle filter algorithm is presented in Algorithm~\ref{alg:particle_filter}.

\subsection{Particle smoother}
Any particle smoother can be used to estimate \eqref{eq:grad_ll} such as the Path-space smoother \cite{Kitagawa1996}, the Forward Filtering Backward Smoothing \cite{Doucet2000OnSM} or the Forward Filtering Backward Simulation algorithm \cite{Godsill2004MonteCS}.
Additionally, because estimating \eqref{eq:grad_ll} amounts to computing a smoothed expectation of an additive functional, we can also use very efficient forward-only SMC smoothers such as the PaRIS algorithm and its pseudo-marginal extensions \cite{Olsson2014EfficientPO,gloaguen2022pseudo}.
For the sake of simplicity, we opt for the Path-space smoother. 
With $\xi^i_{1:T}$ the ancestral line of $\xi^i_{T}$, the following loss function is an estimator of the score, and can be optimized by deep learning frameworks through automated differentiation:
$$
	\widehat {\nabla_\theta \log p_\theta(Y_{1:T})_k^N} = \sum_{i=1}^N \omega_T^i\nabla_\theta\log p_\theta(\xi^i_{1:T}, Y^{k}_{1:T})\,,
$$

\subsection{Stochastic Gradient Descent for online estimation}
An appealing application of the last layer approach is recursive maximum likelihood estimation, i.e., where new observations are used only once to update the estimator of the unknown parameter $\theta$. In \cite{Brosse2020OnLA}, the authors used in particular Stochastic Gradient Descent (SGD) and Stochastic Gradient Langevin Dynamics to update the estimation of $\theta$ and perform uncertainty quantification.

In state space models, recursive maximum likelihood estimation produces a sequence $\lbrace\theta_k\rbrace_{k\geq 0}$ of parameter estimates writing, for each new observation $Y_{k},~k\geq 1$,
$$
	\theta_{k} = \theta_{k-1} + \gamma_k \nabla_\theta \ell_{\theta}(Y_k | Y_{0:k - 1}) \,,
$$
where $\ell_{\theta}(Y_k | Y_{0:k - 1})$ is the loglikelihood for the new observation given all the past, and $\lbrace\gamma_k\rbrace_{k\geq 1}$ are positive step sizes such that $\sum_{k \geq 1}\gamma_k = \infty$ and $\sum_{k \geq 1}\gamma_k^2 < \infty$. The practical implementation of such an algorithm, where $\nabla_\theta\ell_{\theta}(Y_k | Y_{0:k - 1})$ is approximated using the weighted samples $\{(\xi^{\ell}_k,\omega^{\ell}_k)\}_{\ell=1}^N$ can be found for instance in \cite{gloaguen2022pseudo}. The PaRIS algorithm proposed in \cite{Olsson2014EfficientPO} allows to use the weighted samples $\{(\xi^{\ell}_k,\omega^{\ell}_k)\}_{\ell=1}^N$ and some statistics $\{\tau^{\ell}_k\}_{\ell=1}^N$ on-the-fly to approximate $\nabla_\theta \ell_{\theta}(Y_k | Y_{0:k - 1})$ either using rejection sampling approaches or importance sampling steps.

Although this algorithm is very efficient to update parameters recusrively, it is computationally intensive and therefore fits particularly well our last layer approach as it would be intractable for very high dimensional latent states.

\begin{algorithm}
	\caption{Particle filter}
	\label{alg:particle_filter}
	\KwIn{$\theta, Y_{1:T}, \widetilde U_{1:T}$}
	\KwOut{$(\xi_{1:T}^l, \omega_T^l)_{l=1}^N$}
	$\xi_0^l \sim \rho_0$\;
	$\omega_0^{\ell} \propto \chi\left(\xi^{\ell}_0\right)\ell_0 \left(\xi^{\ell}_0\right)/ \rho_0 \left(\xi^{\ell}_0\right)$\;
	\For{$k \gets 1$ \KwTo $T$}{
		$I_k^l \sim \mathbb{P}(I_k^l=j) = \omega_{k-1}^j$\;
		$\xi_k^l \sim p_k(\xi_{k-1}^{I_k^l}, \widetilde U_k)$\;
		$\omega_k^l \gets \ell_k (\xi_k^l) / \sum_{l=1}^N \ell_k (\xi_k^l)$\;
	}
\end{algorithm}

\section{Experiments}
\label{sec:exp}
\subsection{Data}
\label{sub:data}
We benchmarked our approach on the public Electricity Transformer Temperature (ETT) Dataset, designed in \cite{Zhou2021Informer} around the forecasting of Oil temperature based on hourly power load records (ETTh1 subset).
We drew samples composed of a 24 hour long lookback window, where models have access to both commands and observations, followed by a 24 hour long forecasting period, where their performances are compared to the ground truth.

\subsection{Models}%
\label{sub:models}

\textbf{The Input model} is a $L=3$ layered GRU model, as defined in the deep learning framework PyTorch\footnote{\href{https://pytorch.org/docs/stable/generated/torch.nn.GRU.html}{https://pytorch.org/docs/stable/generated/torch.nn.GRU.html}}: for all $1 \leq \ell \leq L$ and all $1 \leq t \leq T$,
\begin{align*}
	r^\ell_t        & = \sigma(W_{ir} U^{\ell - 1}_t + b_{ir} + W_{hr} U^{\ell}_{t-1} + b_{hr})                 \\
	z^\ell_t        & = \sigma(W_{iz} U^{\ell - 1}_t + b_{iz} + W_{hz} U^{\ell}_{t-1} + b_{hz})                 \\
	n^\ell_t        & = \mathrm{tanh}(W_{in} U^{\ell - 1}_t + b_{in} + r^\ell_t (W_{hn} U^\ell_{t-1} + b_{hn})) \\
	\tilde U^\ell_t & = (1-z^\ell_t) n^\ell_t+z^\ell_t U^\ell_{t-1}
\end{align*}
where $\varphi = \{(W_{is}, b_{is}, W_{hs}, b_{hs}), s \in \{r, z, n\}\}$ are unknown parameters, and $\sigma$ is the sigmoid function.
The first layer of the network is assimilated to the input vectors, $\widetilde U_t^0 \equiv U_t$ and $\widetilde U^\ell_0 \equiv 0$.
% where $\varphi = \{W_{ir}, b_{ir}, W_{hr}, b_{hr}, W_{iz}, b_{iz}, W_{hz}, b_{hz}, W_{in}, b_{in}, W_{hn}, b_{hn}\}$ are unknown parameters
The input dimension $d_\textnormal{in}=6$ corresponds to the number of power load records of the dataset, we set the output dimension to 6 as well.
In order to estimate the parameters $\varphi$, we introduce an auxiliary GRU layer responsible for computing oil temperature predictions.
During the training, me minimize the cost function $\mathcal{L}_{\mathrm{input}}(\varphi) = \sum_{i=1}^{N_{\texttt{sample}}} \|\texttt{model}_{\varphi}(U^i_{1:T}) - Y^i_{1:T}\|^2$ where for each sample $1 \leq i \leq N_{\texttt{sample}}$ in the dataset, $\texttt{model}_\varphi(U^i_{1:T})$ is the prediction associated with $Y^i_{1:T}$ obtained with this deterministic model.

\textbf{The State Space model} is implemented using PyTorch's RNN and Linear layers, in order to use auto differentiation.
We chose the following form for $f$ and $g$:
\begin{align*}
	g_\theta &: X_{t-1}, \widetilde U_t \mapsto \tanh(W_gx X_{t-1} + b_gx + W_gu \widetilde U_t + b_gu) \\
	f_\theta &: X_t \mapsto  \sigma(W_f X_t + b_f)
\end{align*}
% where $\theta = \{W_{gx}, b_{gx}, W_{gu}, b_{gu}, W_f, b_f\}$ are unknown parameters.
In this form, since the update rule for both $\Sigma_x$ and $\Sigma_y$ are available explicitly, we compute the following at each training step instead of using gradient descent:
\begin{align*}
	\Sigma_x &= N^{-1} \sum_{l=1}^N \sum_{k=1}^T (\tanh^{-1}(\xi_t^l) - g_{\hat \theta}(\xi^l_{t-1}, \widetilde U_t))^2 \omega_T^l \\
	\Sigma_y &= N^{-1} \sum_{l=1}^N \sum_{k=1}^T (Y_t - f_{\hat \theta}(\xi^l_t))^2 \omega_T^l
\end{align*}
For the initial weights computation, we use $\chi = \rho_0$.
All following experiments were computed with $N=100$ particles.

\subsection{Trainings}
\label{sub:trainings}
All training experiments are conducted with a batch size of 32, using the Adam optimizer introduced in \cite{Kingma2015AdamAM}.
The learning rate was chosen using a simple grid search.
We train models for a maximum of 50 epochs, and employ early stopping to prevent overfit.

\subsection{Evaluations}%
\label{sub:evaluations}

In this section, we illustrate the ability of our model to capture the distribution of future observations, by evaluating the benchmarked models on the following protocol:
we draw 48 hours long samples $(u_{1:48}, y_{1:48})$ from the validation dataset, composed of a 24 hour long lookback window $(u_{1:24}, y_{1:24})$, containing historic commands and observations, and a predictions window where only future commands are available $(u_{25:48})$.
Each model produces a 24 hour long forecast, which is compared to the ground truth to compute the Mean Squared Error (MSE) and Mean Absolute Error (MAE) criteria $\mathcal{L}(y_{25:48}, \texttt{model}(u_{1:48}, y_{1:24}))$, reported in Table~\ref{tab:ci_comparison}.

For our proposed model, one step predictions can be performed by approximating the predictive density $p_{\theta,\varphi}(y_{t+1}|U_{1:t+1},Y_{1:t})$ by
$$
	p^N_{\widehat\theta,\widehat\varphi}(y_{t+1})= \sum_{i=1}^{N}\omega_t^i p_{\widehat\theta,\widehat\varphi}(y_{t+1}|\xi_t^i,U_{t+1})\,,
$$
where $ p_{\widehat\theta,\widehat\varphi}(y_{t+1}|\xi_t^i,U_{t+1})$ is the predictive distribution of $Y_{t+1}$ described in Section~\ref{sub:proposed_architecture}.
Although predictions given the previous time step provide good performances, it is limited as many applications require multi-steps forecasts.
In order to explore longer ranges, we can draw $N$ independent samples from $\sum_{i=1}^{N}\omega_t^i p_{\widehat\theta,\widehat\varphi}(y_{t+p}|\xi_t^i,U_{t+1:t+p})$, for $p>1$.
As $p$ increases, the accuracy of our predictions decreases, as our model no longer has access to the observations.
We report MSE and MAE criteria by averaging the forecasts of these $N$ draws.
The associated confidence intervals are displayed in Figure~\ref{fig:filter_k+24} for $1\leq p \leq 24$.

We compared our model with MC Dropout methods, by implementing recurrent dropout layers as described in \cite{Gal2016NIPS}, with dropout values of $p_\textnormal{drop}=0.05$ and $p_\textnormal{drop}=0.01$.
The training procedure is similar to traditional recurrent models ; during inference, we draw $N=100$ samples from the dropout layers, and compute the same average forecasts and confidence intervals as our model.
Despite being based on the same deep learning architecture, the MC dropout model is still largely overconfident, while our proposed model provide more credible empirical confidence intervals.
We also experimented with a linear Hidden Markov Model (HMM), without reaching performances on par with the other approaches.

\begin{figure}[htpb]
	\centering
	\caption{Our architecture combining a generic input model with a state space model on the last layer.}
	\includegraphics[width=0.7\linewidth]{architecture.png}
	\label{fig:architecture}
\end{figure}

\begin{figure}[htpb]
	\centering
	\caption{Prediction of Oil temperature (ETT Dataset) given observations in the lookback window ($t<24$) and without ($t>24$).
		Since re sampling of particles is no longer available at that point, the uncertainty grows for our model.
		As a comparison, we plotted the confidence intervals produced by the MC Dropout model (for $p_\textnormal{drop}=0.01$).
		Aggregated results on the entire validation set for the MSE and MAE criteria can be found in Table~\ref{tab:ci_comparison}.}
	\includegraphics[width=\linewidth]{filter_kp24_ett.png}
	\label{fig:filter_k+24}
\end{figure}

\begin{table}[htpb]
	\centering
	\caption{Comparison of MSE, MAE and computation time of our model against the benchmarked MC Dropout methods and HMM.
		This table provide aggregated results of the simulation presented in Figure~\ref{fig:filter_k+24} on the entire validation set.
		Two versions of the dropout model were evaluated, with dropout values $p_\textnormal{drop}=0.05$ and $p_\textnormal{drop}=0.01$.
		Mean values of the estimators are displayed along with their variance.}
	\label{tab:ci_comparison}
	\begin{tabular}{llll}
		\toprule
		$(\times 10^{-2})$ & MSE             & MAE             & Computation time  \\
		\toprule
		SMCL (ours)        & $7.74 \pm 9.84$ & $21.2 \pm 12.1$ & $210 ms \pm 75.7$ \\
		MCD $p=0.01$       & $8.20 \pm 14.0$ & $20.9 \pm 14.0$ & $193 ms \pm 60.4$ \\
		MCD $p=0.05$       & $9.76 \pm 10.5$ & $23.4 \pm 13.4$ & $193 ms \pm 60.4$ \\
		HMM                & $76.2 \pm 28.1$ & $65.6 \pm 26.3$ & $994 ms \pm 21.4$ \\
		\bottomrule
	\end{tabular}
\end{table}

%Evaluations listed in priority order
%\begin{enumerate}
%	\item Compare confidence interval with MC-dropout model (soit LSTM dropout classique, soit en enlevant la derniere couche)
%	\item Compare with ARIMA/classic stat model
%	\item Compare MSE (average on particles) with classic finetuning: sample particles for half a week. For the second half, observations are not available at all ; thus we either take the mean of the predictions associated with each particles, or sample from the observation model and take the mean.
%	\item Compare linear SMC with kalman filter, sample under the gaussian law, plot boxplot
%\end{enumerate}

\section{Conclusion}%
\label{sec:conclusion}

In this letter, we introduced a decoupled architecture for uncertainty estimation on a time series dataset.
Our deep neural network backbone is responsible for extracting high level features, while particle filtering allows modelling recurrent non linear uncertainty.
Our proposed model improves confidence interval quality, compared to MC Dropout methods, while remaining simple and efficient to train, compared to VI alternatives.

We demonstrate the potential behind implementing latent space models as a modified RNN cell ;
more complex architectures, such as the GRU network used in the input model, or LSTM cells, are left for future works.
Likewise, the Path-space smoother could be replaced by faster and more performant alternatives described above.

Our decoupled architecture enables incorporating uncertainty estimation to an already trained network.
This opens the door to multiple, cheap finetuning of last layers parameters, from a global pretraining.
%For our application, this could translate in a generic training of the input model on an entire year of weather and building records, followed by season specific finetunings.

\clearpage
\bibliographystyle{IEEEtran}
\bibliography{refs.bib}
\end{document}
