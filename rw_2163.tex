\documentclass{article}
% Packages
\usepackage{amsmath} % Math environments
\usepackage{amsfonts, dsfont} % Math fonts
\usepackage{authblk} % Author and affiliations
\usepackage{hyperref} % Links
\usepackage{graphicx} % Include graphics
\usepackage{apalike} % Reference styling
\usepackage{booktabs}
\usepackage[a4paper, total={5in, 9in}]{geometry}

% Commands
\providecommand{\keywords}[1]{\textbf{\textit{Index terms---}} #1}

\begin{document}

We would like to thank the reviewer for their thorough reading of our paper.
We took note of their remarks which improved the clarity and precision of our work.

We also agree with the reviewer that "The experiment [was] very small [...] more complex problem".
In the original version of the paper, we focused on a specific application, mainly due to space constraints \footnote{We would like to highlight that although our original dataset contains a limited number of samples, each one represents a week's worth of hourly data for 10 different time series.}.
In order to expand on our validation experiments, we benchmarked our model on the \textit{Appliances energy prediction}\footnote{https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction} public dataset from the UCI Machine Learning Repository.
Indoor temperature and humidity records are matched with various weather variables, such as outdoor temperature, pressure or wind speed, and building consumption information (for appliance and lights).
We compared our model with the LSTM Dropout on the indoor temperature forecasting task, and reported our results in Table~\ref{tab:comparison}, which comfort our first experiment.
As advised by the reviewer, computation times for each training epoch are reported, showing that our model is slower, without being prohibitive in practice.
We hope that this new experiment provides more convincing numerical validation.

It is true that "Even for lower dimensional state space models, Monto Carlo sampling is computationally expensive to perform at training time".
These expensive computations are one of the main motivation for our paper, which we address by decoupling the last SMC layer from the rest of the model.
During \textbf{training}, the model's backbone and the uncertainty quantification layer are fitted separately.
This way, expensive SMC computations are limited to finetuning only a few parameters, allowing for reasonable training times.
During {\bf inference} on the forecasting task presented, we propagate multiple particles in parallel, which is very efficient thanks deep learning frameworks.
These remarks will be added at the end of Section 2 for better clarity.

As stated by the reviewer we "assume the state space model follows a Gaussian distribution".
However, the SMC approach allows for any noise distribution, provided the transition and emission densities can be evaluated pointwise.
We focused on the Gaussian case but extension to noise with heavier tails is straightforward.
We propose to add these clarifications at the end of Section 2.1.

The reviewer finds "the assumption and motivation stated in this paper are both incorrect".
We agree that some parts of the presentation were a bit confusing in the original version, but would like to insist on the fact that our assumptions and motivations are correct in our opinion, and the topic of a very active area of research.
In the revised version of the paper we propose to provide a clear motivation, by replacing the pointed confusing paragraph with the following statement: "The use of latent data models and Bayesian simulation procedures allows to approximate the distributions of future observations given past records and to provide uncertainty estimation, which is a challenging and active area of research in deep learning".

\begin{table}[htpb]
	\centering
	\caption{Comparison between LSTM Dropout and our SMC model on the new \texttt{energy} dataset.}
	\label{tab:comparison}
	\begin{tabular}{lllll}
		\toprule
		             & PICP            & MPIW    & MAE             & Training Epoch \\
		\toprule
		SMCL (ours)  & $\textbf{0.83}$ & $1.05$ & $0.84$          & 15s            \\
		MCD $p=0.15$ & $0.23$          & $0.56$  & $\textbf{0.82}$ & \textbf{3s}    \\
		\bottomrule
	\end{tabular}
\end{table}

\bibliographystyle{apalike}
\bibliography{references}
\end{document}
