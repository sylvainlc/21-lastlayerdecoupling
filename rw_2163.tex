\documentclass{article}
% Packages
\usepackage{amsmath} % Math environments
\usepackage{amsfonts, dsfont} % Math fonts
\usepackage{authblk} % Author and affiliations
\usepackage{hyperref} % Links
\usepackage{graphicx} % Include graphics
\usepackage{apalike} % Reference styling
\usepackage{booktabs}

% Commands
\providecommand{\keywords}[1]{\textbf{\textit{Index terms---}} #1}

\title{}

\author{}
%\affil{Samovar, T\'el\'ecom SudParis, CITI, TIPIC, Institut Polyechnique de Paris}
\date{}

\begin{document}
\maketitle

We would like to thank the reviewer for their thorough reading of our paper.
We took note of their remarks which helped improve the clarity and precision of our work.

We also agree with the reviewer that "The experiment [was] very small and focused on a very specific problem. Authors should validate their proposed technique on a well-know, more complex problem".
In the original version of the paper, we focused on a specific application, yet challenging in our opinion, mainly due to space constraints \footnote{We would like to highlight that although our original dataset contains a limited number of samples, each one represents a week's worth of hourly data for 10 different time series.}.
In order to expand on our validation experiments, we benchmarked our model on the \textit{Appliances energy prediction}\footnote{https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction} public dataset from the UCI Machine Learning Repository.
Indoor temperature and humidity records are matched with various weather variables, such as outdoor temperature, pressure or wind speed, and building consumption information (for appliance and lights).
We compared our model with the LSTM Dropout on the indoor temperature forecasting task, and reported our results in Table~\ref{tab:comparison}, which comfort our first experiment.
As advised by the reviewer, computation times for each training epoch are reported, showing that our model is slower, without being prohibitive in practice.
We would like to thank the reviewer for this comment which helped improving the paper and hope that this new experiment provides more convincing numerical validation.

It is true that  "Even for lower dimensional state space models, Monto Carlo sampling is computationally expensive do perform at training time".
The famously expensive computations of Sequential Monte Carlo (SMC) sampling is one of the main motivation for our paper, which we address by decoupling SMC computations from the rest of the model:
\begin{itemize}
	\item \textbf{training}: we were able to reach reasonable training times by separately training the model's backbone from the last uncertainty quantification layer.
	      This way, expensive SMC computations are limited to finetuning only a few parameters.
	      The computational time is indeed larger than for the standard RNN (XXX give the order of magnitude here) but does not increase dramatically.
	      Additionally, we aim at implementing recent advances in SMC that allow smoothing with a linear computational complexity, see [].
	\item \textbf{inference}: for the forecasting task presented in our paper, we only need to propagate multiple particles at the same time, which is very efficient thanks to the inherent parallel implementation of deep learning frameworks.
\end{itemize}
These remarks will be added at the end of Section 2 for better clarity.

As stated by the reviewer we "assume the state space model follows a Gaussian distribution". However, the SMC approach can be used for any noise distribution as long as the transition and emission densities can be evaluated pointwise (it has also been proved recently that smoothing can be performed when only an estimator of the densities is available using pseudo-marginal techniques, see \cite{papier gloaguen lecorff Olsson}). We focused on the Gaussian case  in our setting as it provides good performance but extension to noise with heavier tails is straightforward. We propose to add these clarifications at the end of Section 2.1.

The reviewer finds "the assumption and motivation stated in this paper [...] both incorrect".
We agree that some parts of the presentation were a bit confusing in the original version but would like to insist on the fact that our assumptions and motivations are correct in our opinion and also the topics of a very active area of research.
In the revised version of the paper we propose to provide a clear motivation.
We propose for instance to replace the paragraph "These recurrent architectures are able to approximate complex nonlinear time series, but suffer from overconfidence when evaluated outside of their training observations. Bayesian statistics aim at mitigating this drawback by providing uncertainty estimation \cite{Hinton1995BayesianLF}." by the following statement "XXX".

\begin{table}[htpb]
	\centering
	\caption{Comparison between LSTM Dropout and our SMC model on the new \texttt{energy} dataset.}
	\label{tab:comparison}
	\begin{tabular}{lllll}
		\toprule
		             & PICP            & MPIW    & MAE             & Training Epoch \\
		\toprule
		SMCL (ours)  & $\textbf{0.80}$ & $0.101$ & $0.84$          & 15s            \\
		MCD $p=0.15$ & $0.23$          & $0.56$  & $\textbf{0.82}$ & \textbf{3s}    \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{itemize}
	\item Reformuler les motivations pour expliquer clairement l'intérêt des modèles d'état ; souligner la différence entre généralisation et overconfidence.
	\item Le remarcier pour les bruits multimodals ; expliquer qu'on peut s'adapter à n'importe quel bruit en changeant les équations
\end{itemize}

\bibliographystyle{apalike}
\bibliography{references}
\end{document}
